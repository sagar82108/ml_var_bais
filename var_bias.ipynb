{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18a8d6-c624-4c4c-b2e3-e11aaf29cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "**Overfitting:** Model learns training data too well, performs poorly on new data. Caused by complexity, noise. Mitigate with simpler models, more data, regularization.\n",
    "\n",
    "**Underfitting:** Model is too simple, performs poorly on training and new data. Caused by simplicity, inadequate training. Mitigate with more complex models, more data, feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d1707-a24e-4a15-bb73-84f065087dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "To reduce overfitting in machine learning, you can take the following steps:\n",
    "Simplify the Model: Use a simpler model architecture with fewer parameters. For example, switch from a deep neural network to a shallower one.\n",
    "\n",
    "Increase Training Data: If possible, gather more training data. A larger dataset can help the model generalize better.\n",
    "\n",
    "Regularization: Apply regularization techniques like L1 or L2 regularization to penalize large weights or feature magnitudes, preventing the model from fitting noise.\n",
    "\n",
    "Cross-Validation: Use techniques like k-fold cross-validation to tune hyperparameters effectively and evaluate your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745489f-70ca-4428-b3d3-1dacbacae7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting occurs in machine learning when a model is too simple to capture the underlying patterns in the data, \n",
    "resulting in poor performance. It means that the model fails to learn even the training data adequately.\n",
    "\n",
    "Characteristics of Underfitting:\n",
    "\n",
    "High Training Error: The model struggles to fit the training data, resulting in a high training error.\n",
    "\n",
    "High Testing Error: It also performs poorly on new, unseen data, leading to a high testing error.\n",
    "\n",
    "Simplicity: The model is overly simplistic and lacks the capacity to represent the complexity of the data.\n",
    "\n",
    "Failure to Capture Patterns: It may not even capture the basic patterns or relationships present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26d3de-65ef-4aa5-9e46-e328d4499896",
   "metadata": {},
   "outputs": [],
   "source": [
    "The bias-variance tradeoff in machine learning is a balance between two types of errors:\n",
    "\n",
    "Bias arises from simplifying a model too much, leading to underfitting and systematic errors.\n",
    "\n",
    "Variance results from making a model too complex, leading to overfitting and poor generalization.\n",
    "\n",
    "Finding the right balance between bias and variance is crucial for creating models that perform well on new, unseen data.\n",
    "Underfitting and overfitting are the two extremes to avoid.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f1ce7-9c05-46db-9f04-fd8e448b0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias and variance are two key aspects of a machine learning model's behavior:\n",
    "\n",
    "- **Bias**: Low complexity, underfitting, poor performance.\n",
    "- **Variance**: High complexity, overfitting, good training but poor testing performance.\n",
    "\n",
    "Balancing them is crucial for building models that generalize effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840862e-1f81-469a-a29d-d5773f7497cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization in machine learning prevents overfitting by adding penalties to a model's complexity. Common techniques include L1 and L2 regularization, dropout for neural networks, early stopping, and cross-validation. They help balance fitting the training data and generalizing to new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
